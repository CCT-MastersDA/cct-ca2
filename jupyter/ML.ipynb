{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888c77ff-fbc1-4f94-8620-9628d1222b70",
   "metadata": {},
   "source": [
    "# CA2 - ML on Agriculture in Ireland and EU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f1e7e-e1b6-40f6-bbd1-0d0a65897e9c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sentiment analysis on data x\n",
    "\n",
    "2 ML models on data y\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cab9fe-ef9f-446e-aa37-ee75a8272cda",
   "metadata": {},
   "source": [
    "## Auxiliary Functions\n",
    "\n",
    "In this section, the auxiliary functions used in this notebook were implemented.\n",
    "\n",
    "* Instructions to use the Twitter API:\n",
    "\n",
    "- There should exist a file called .twitter_env in the machine's home directory with the following keys:\n",
    "\n",
    "    ```\n",
    "    API_KEY=***\n",
    "    API_KEY_SECRET=***\n",
    "    BEARER_TOKEN=***\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "308f0109-a00f-49d7-bfcf-89def999326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "from dotenv import dotenv_values\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# use a logger to help debugging\n",
    "logger = logging.getLogger('mylogger')\n",
    "\n",
    "# set logger level\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# path to the current directory\n",
    "CURR_PATH = os.path.abspath(os.getcwd())\n",
    "\n",
    "# path to the users directory\n",
    "HOME_DIR = str(Path.home())\n",
    "\n",
    "# path to dataset dir\n",
    "DATASET_DIR = os.path.join(CURR_PATH, 'datasets')\n",
    "\n",
    "# twitter env file\n",
    "TWITTER_ENV_FILE = '.twitter_env'\n",
    "\n",
    "# twitter recent search api url\n",
    "TWITTER_API_SEARCH_URL = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "\n",
    "def getEnvObj():\n",
    "    env_path = os.path.join(HOME_DIR, TWITTER_ENV_FILE)\n",
    "\n",
    "    if not os.path.exists(env_path):\n",
    "        logger.error(F'Unable to read the environment file. Make sure a { TWITTER_ENV_FILE } file exists in your home directory.')\n",
    "        return None\n",
    "\n",
    "    return dotenv_values(env_path)\n",
    "\n",
    "def createTwitterConfigFile():\n",
    "    config = getEnvObj()\n",
    "\n",
    "    if config is None:\n",
    "        logger.error(\"Unable to set Twitter's config file.\")\n",
    "        return False\n",
    "\n",
    "    twitter_keys = f'''keys:\n",
    "    access_token: {config[\"API_KEY\"]}\n",
    "    access_token_secret: {config[\"API_KEY_SECRET\"]}\n",
    "    bearer_token: {config[\"BEARER_TOKEN\"]}\n",
    "    '''\n",
    "    keys_path = os.path.join(HOME_DIR, '.twitter-keys.yaml') \n",
    "    with open(keys_path, 'w+') as file:\n",
    "        file.write(twitter_keys)\n",
    "    logger.info(f\"Twitter keys file '{ keys_path }' updated!\")\n",
    "\n",
    "    return True\n",
    "\n",
    "def bearerAuth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    config = getEnvObj()\n",
    "    \n",
    "    if config is None:\n",
    "        raise Exception('Unable to create Bearer authorization object.')\n",
    "\n",
    "    r.headers['Authorization'] = f\"Bearer { config['BEARER_TOKEN'] }\"\n",
    "    r.headers['User-Agent'] = 'v2RecentSearchPython'\n",
    "\n",
    "    return r\n",
    "\n",
    "def connectToEndpoint(url, params_dict={}):\n",
    "    response = requests.get(url, auth=bearerAuth, params=params_dict)\n",
    "\n",
    "    if response is None:\n",
    "        raise Exception('Invalid response.')\n",
    "\n",
    "    logger.info(response.status_code)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def getRecentTweets(params={}, outfile=''):\n",
    "    # querying the API\n",
    "    json_response = connectToEndpoint(TWITTER_API_SEARCH_URL, params)\n",
    "  \n",
    "    # save json to file if not empty\n",
    "    saveJsonToFile(json_response, outfile)\n",
    "    \n",
    "    print(f\"{ len(json_response['data']) } tweets retrieved!\")\n",
    "    \n",
    "    return json_response\n",
    "\n",
    "def saveJsonToFile(json_data, outfile):\n",
    "    if len(outfile) == 0:\n",
    "        logger.warning('Output filename is empty!')\n",
    "        return\n",
    "\n",
    "    with open(outfile, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def convertJsonToString(json_obj):\n",
    "    return json.dumps(json_obj, indent=4, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea23a9-dfcb-4858-91ba-b86d5ee575ec",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "In this section, the Twitter API was used to collect tweets from the last few days that will be used for the sentiment analysis.\n",
    "\n",
    "The purpose of this search was to find tweets about inflation or food price, which relate to the agriculture topic.\n",
    "\n",
    "However, there is a limitation in the quality of data being collected as the query API feature performs a search by token which can result in tweets about any topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afcb3c1-e5ce-48c4-83da-8ab61647e81e",
   "metadata": {},
   "source": [
    "### Data Collection - Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "043b43c0-c2e2-43ed-9546-c374589a938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tweets retrieved!\n"
     ]
    }
   ],
   "source": [
    "query_params = {\n",
    "    'query' : '(inflation OR \"food price\" OR \"agriculture\") Europe -is:retweet -has:media lang:en',\n",
    "    'tweet.fields': 'author_id', \n",
    "    'user.fields': 'name',\n",
    "    \"max_results\":\"100\",\n",
    "}\n",
    "\n",
    "data = getRecentTweets(query_params, os.path.join(DATASET_DIR, 'twitter_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49783c76-5934-4148-8bb7-ce82ecac2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets = [d['text'] for d in data['data']]\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd24ae81-2d30-4886-bf5a-0df9e1505857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweets    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50d826-55f8-4fba-ad7d-00023f3855db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "data = vectorizer.fit_transform(df['tweets'])\n",
    "\n",
    "# Display the feature names in sorted order\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd1a8cf5-0968-45f8-bd29-6c711241b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05        0.05        0.05       ...  0.05        0.05\n",
      "   0.05      ]\n",
      " [ 0.05        0.05        0.05       ...  0.05        1.05\n",
      "   0.05      ]\n",
      " [ 0.05        0.05        3.52703678 ...  0.05        0.05\n",
      "   0.05      ]\n",
      " ...\n",
      " [ 0.05        0.05        0.05       ...  1.05        0.05\n",
      "   0.05      ]\n",
      " [ 0.05        1.05       11.31827306 ...  0.05        0.05\n",
      "   0.05      ]\n",
      " [ 0.05        0.05        0.05       ...  0.05        0.05\n",
      "   0.05      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Declare and initialise a variable t\n",
    "t = 20\n",
    "\n",
    "# Declare and initialise an object 'lda' by calling a method LatentDirichletAllocation()\n",
    "lda = LatentDirichletAllocation(n_components = t, learning_method = 'batch', random_state = 42)\n",
    "\n",
    "# Train the model\n",
    "lda.fit(data)\n",
    "\n",
    "# Print all lda components\n",
    "print(lda.components_)\n",
    "\n",
    "# Get all feature names\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c184176-2b61-431b-a88f-6a64803d36c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "canceled r8h8kghyi1 chinese https co get now recession we so\n",
      "Topic 1:\n",
      "than in you and is to inflation europe of the\n",
      "Topic 2:\n",
      "why usa of inflation and europe 10 in to the\n",
      "Topic 3:\n",
      "high energy but europe inflation we to as in the\n",
      "Topic 4:\n",
      "and europe be not should has inflation this is the\n",
      "Topic 5:\n",
      "with that of inflation is has in europe and the\n",
      "Topic 6:\n",
      "an as can have it here at the but to\n",
      "Topic 7:\n",
      "for this war in to europe inflation co https the\n",
      "Topic 8:\n",
      "china to of euros 12 inflation spain billion 2022 10\n",
      "Topic 9:\n",
      "people it in this maybe should first and we to\n",
      "Topic 10:\n",
      "for ukraine agriculture to crisis is that of and the\n",
      "Topic 11:\n",
      "about that not how war europe of inflation in and\n",
      "Topic 12:\n",
      "https and of as but inflation it europe in the\n",
      "Topic 13:\n",
      "least have the well inflation be europe will to in\n",
      "Topic 14:\n",
      "https co and that europe inflation to the is in\n",
      "Topic 15:\n",
      "as be russia not are will for europe in inflation\n",
      "Topic 16:\n",
      "costs amp is europe worse be will higher inflation the\n",
      "Topic 17:\n",
      "will economic has with in the europe of and to\n",
      "Topic 18:\n",
      "announces 10 ease pain to spain package inflation co https\n",
      "Topic 19:\n",
      "so war is of and the europe in to inflation\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic {}:\" .format(topic_idx))\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ca3d0-b7cc-45a2-8b46-ea3679f2a553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
